{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Bvm8nC_EDZ",
        "outputId": "b734fee7-60ae-4474-97c7-a7e15bad14b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Aug  5 19:18:30 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwi-nDjIAwBJ",
        "outputId": "cf6f26d0-58f3-40d9-aeaf-9338b78c1597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xgboost 2.1.1 requires nvidia-nccl-cu12; platform_system == \"Linux\" and platform_machine != \"aarch64\", which is not installed.\n",
            "accelerate 0.32.1 requires numpy<2.0.0,>=1.17, but you have numpy 2.1.0 which is incompatible.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 2.1.0 which is incompatible.\n",
            "arviz 0.18.0 requires numpy<2.0,>=1.23.0, but you have numpy 2.1.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 2.1.0 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.0 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires numpy<2,>=1, but you have numpy 2.1.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.0 which is incompatible.\n",
            "pandas 2.1.4 requires numpy<2,>=1.22.4; python_version < \"3.11\", but you have numpy 2.1.0 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 2.1.0 which is incompatible.\n",
            "scikit-learn 1.3.2 requires numpy<2.0,>=1.17.3, but you have numpy 2.1.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.0 which is incompatible.\n",
            "transformers 4.42.4 requires numpy<2.0,>=1.17, but you have numpy 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall numpy -y\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPdtg2XEBLMs",
        "outputId": "fc683591-cdd1-4b66-dee4-288b9750b441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas-stubs in /usr/local/lib/python3.10/dist-packages (2.1.4.231227)\n",
            "Collecting pandas-stubs\n",
            "  Downloading pandas_stubs-2.2.2.240807-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from pandas-stubs) (2.1.0)\n",
            "Requirement already satisfied: types-pytz>=2022.1.1 in /usr/local/lib/python3.10/dist-packages (from pandas-stubs) (2024.1.0.20240417)\n",
            "Downloading pandas_stubs-2.2.2.240807-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.1/157.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas-stubs\n",
            "  Attempting uninstall: pandas-stubs\n",
            "    Found existing installation: pandas-stubs 2.1.4.231227\n",
            "    Uninstalling pandas-stubs-2.1.4.231227:\n",
            "      Successfully uninstalled pandas-stubs-2.1.4.231227\n",
            "Successfully installed pandas-stubs-2.2.2.240807\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pandas-stubs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrqJAedA_IM1",
        "outputId": "5c054d77-bc46-45ac-c7eb-b050ad25cf9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.0/301.0 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.6/318.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m746.9/746.9 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.6/255.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.7/239.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.1/869.1 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q inference-gpu[yolo-world]==0.9.12rc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz6WAmz3_paj"
      },
      "outputs": [],
      "source": [
        "!pip install -q supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "id": "J4hmyhvV_7pR",
        "outputId": "4f2ae8f3-87c8-4793-9d88-57c647908e02"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[08/20/24 09:06:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Your inference package version \u001b[1;36m0.9\u001b[0m.12rc1 is out of date! Please upgrade \u001b]8;id=566443;file:///usr/local/lib/python3.10/dist-packages/inference/core/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=618641;file:///usr/local/lib/python3.10/dist-packages/inference/core/__init__.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                    \u001b[0m         to version \u001b[1;36m0.16\u001b[0m.\u001b[1;36m2\u001b[0m of inference for the latest features and bug fixes by \u001b[2m              \u001b[0m\n",
              "\u001b[2;36m                    \u001b[0m         running `pip install --upgrade inference`.                              \u001b[2m              \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08/20/24 09:06:14] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Your inference package version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>.12rc1 is out of date! Please upgrade <a href=\"file:///usr/local/lib/python3.10/dist-packages/inference/core/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.10/dist-packages/inference/core/__init__.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.16</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of inference for the latest features and bug fixes by <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         running `pip install --upgrade inference`.                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import cv2\n",
        "import supervision as sv\n",
        "\n",
        "from tqdm import tqdm\n",
        "from inference.models.yolo_world.yolo_world import YOLOWorld\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNcxCY79Bip2"
      },
      "outputs": [],
      "source": [
        "model = YOLOWorld(model_id=\"yolo_world/l\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCIZmSacDBzM",
        "outputId": "09e4640c-231e-4242-a029-a45908607600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SupervisionWarnings: BoundingBoxAnnotator is deprecated: `BoundingBoxAnnotator` is deprecated and has been renamed to `BoxAnnotator`. `BoundingBoxAnnotator` will be removed in supervision-0.26.0.\n"
          ]
        }
      ],
      "source": [
        "BOUNDING_BOX_ANNOTATOR = sv.BoundingBoxAnnotator(thickness=2)\n",
        "LABEL_ANNOTATOR = sv.LabelAnnotator(text_thickness=1, text_scale=1, text_color=sv.Color.BLACK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnMSHaA8HZIh"
      },
      "outputs": [],
      "source": [
        "SOURCE_VIDEO_PATH = f\"/content/cheq.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqhXnwKuJYZQ",
        "outputId": "2c8f6711-ee49-420e-ca9a-66bc2c9a8b3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:04<00:00, 72.1MiB/s]\n"
          ]
        }
      ],
      "source": [
        "classes = [\"person\",\"face\"]\n",
        "model.set_classes(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMrvwglaJ8xe"
      },
      "outputs": [],
      "source": [
        "TARGET_VIDEO_PATH = f\"/content/cheq_summ.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXrulH8RJ2S0",
        "outputId": "1d89ca2c-3fbd-4fff-c04b-f91f2c57b097"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2611/2611 [01:23<00:00, 31.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summarized video saved to /content/1_summry.mp4\n"
          ]
        }
      ],
      "source": [
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "width, height = video_info.resolution_wh\n",
        "frame_area = width * height\n",
        "\n",
        "# List to store frames with detected humans\n",
        "detected_frames = []\n",
        "\n",
        "for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
        "    results = model.infer(frame, confidence=0.5)\n",
        "    detections = sv.Detections.from_inference(results).with_nms(threshold=0.3)\n",
        "    detections = detections[(detections.area / frame_area) < 0.10]\n",
        "\n",
        "    if len(detections) > 0:\n",
        "        # Annotate frame if required\n",
        "        annotated_frame = frame.copy()\n",
        "        annotated_frame = BOUNDING_BOX_ANNOTATOR.annotate(annotated_frame, detections)\n",
        "        annotated_frame = LABEL_ANNOTATOR.annotate(annotated_frame, detections)\n",
        "\n",
        "        # Store the frame\n",
        "        detected_frames.append(annotated_frame)\n",
        "\n",
        "# Create a summarized video from the detected frames\n",
        "if detected_frames:\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = video_info.fps\n",
        "    out = cv2.VideoWriter(TARGET_VIDEO_PATH, fourcc, fps, (width, height))\n",
        "\n",
        "    for frame in detected_frames:\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "\n",
        "print(f\"Summarized video saved to {TARGET_VIDEO_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unJKU0ZoCapb"
      },
      "outputs": [],
      "source": [
        "def detect_and_extract_frames(video_path, classes, confidence=0.5, nms_threshold=0.3):\n",
        "    frame_generator = sv.get_video_frames_generator(video_path)\n",
        "    video_info = sv.VideoInfo.from_video_path(video_path)\n",
        "    width, height = video_info.resolution_wh\n",
        "    frame_area = width * height\n",
        "\n",
        "    model.set_classes(classes)\n",
        "    detected_frames = []\n",
        "\n",
        "    for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
        "        results = model.infer(frame, confidence=confidence)\n",
        "        detections = sv.Detections.from_inference(results).with_nms(threshold=nms_threshold)\n",
        "        detections = detections[(detections.area / frame_area) < 0.10]\n",
        "\n",
        "        if len(detections) > 0:\n",
        "            detected_frames.append(frame)\n",
        "\n",
        "    return detected_frames, video_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VX8XVjDmCTF",
        "outputId": "ccefb263-63db-4b02-931f-20e8404df11f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4521/4521 [02:44<00:00, 27.42it/s]\n",
            "100%|██████████| 4521/4521 [02:42<00:00, 27.81it/s]\n",
            "100%|██████████| 4521/4521 [02:45<00:00, 27.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final summarized video saved to /content/cheq_summ.mp4\n"
          ]
        }
      ],
      "source": [
        "# Detect humans\n",
        "human_frames, video_info = detect_and_extract_frames(SOURCE_VIDEO_PATH, [\"person\", \"face\"])\n",
        "\n",
        "# Detect nature scenery (replace with actual class names used by your model)\n",
        "nature_frames, _ = detect_and_extract_frames(SOURCE_VIDEO_PATH, [\"tree\", \"mountain\", \"river\"])\n",
        "\n",
        "# Detect vehicles (replace with actual class names used by your model)\n",
        "vehicle_frames, _ = detect_and_extract_frames(SOURCE_VIDEO_PATH, [\"car\", \"bus\", \"bike\"])\n",
        "\n",
        "# Combine all frames\n",
        "all_frames = human_frames + nature_frames + vehicle_frames\n",
        "\n",
        "# Create the final summarized video\n",
        "TARGET_VIDEO_PATH = \"/content/cheq_summ.mp4\"\n",
        "if all_frames:\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = video_info.fps\n",
        "    out = cv2.VideoWriter(TARGET_VIDEO_PATH, fourcc, fps, (video_info.resolution_wh[0], video_info.resolution_wh[1]))\n",
        "\n",
        "    for frame in all_frames:\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "\n",
        "print(f\"Final summarized video saved to {TARGET_VIDEO_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM-cSZnb9LvU"
      },
      "outputs": [],
      "source": [
        "# TWEAKING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtYb7eUK9WCv"
      },
      "outputs": [],
      "source": [
        "def detect_and_extract_frames(frame_batch, classes, confidence=0.5, nms_threshold=0.3):\n",
        "    model.set_classes(classes)\n",
        "    detected_frames = []\n",
        "    for frame in frame_batch:\n",
        "        results = model.infer(frame, confidence=confidence)\n",
        "        detections = sv.Detections.from_inference(results).with_nms(threshold=nms_threshold)\n",
        "        if len(detections) > 0:\n",
        "            detected_frames.append(frame)\n",
        "    return detected_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvvlLD8k9Xeu",
        "outputId": "1ffb22b5-140f-4d82-99dd-e98ca5d4d527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video in batches...\n",
            "Processing frames 1-100 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 101-200 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 201-300 for classes: ['person', 'face']\n",
            "Processing frames 301-400 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 401-500 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 501-600 for classes: ['person', 'face']\n",
            "Processing frames 601-700 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 701-800 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 801-900 for classes: ['person', 'face']\n",
            "Processing frames 901-1000 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 1001-1100 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 1101-1200 for classes: ['person', 'face']\n",
            "Processing frames 1201-1300 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 1301-1400 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 1401-1500 for classes: ['person', 'face']\n",
            "Processing frames 1501-1600 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 1601-1700 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 1701-1800 for classes: ['person', 'face']\n",
            "Processing frames 1801-1900 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 1901-2000 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 2001-2100 for classes: ['person', 'face']\n",
            "Processing frames 2101-2200 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 2201-2300 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 2301-2400 for classes: ['person', 'face']\n",
            "Processing frames 2401-2500 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 2501-2600 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 2601-2700 for classes: ['person', 'face']\n",
            "Processing frames 2701-2800 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 2801-2900 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 2901-3000 for classes: ['person', 'face']\n",
            "Processing frames 3001-3100 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 3101-3200 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 3201-3300 for classes: ['person', 'face']\n",
            "Processing frames 3301-3400 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 3401-3500 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 3501-3600 for classes: ['person', 'face']\n",
            "Processing frames 3601-3700 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 3701-3800 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 3801-3900 for classes: ['person', 'face']\n",
            "Processing frames 3901-4000 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 4001-4100 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 4101-4200 for classes: ['person', 'face']\n",
            "Processing frames 4201-4300 for classes: ['tree', 'mountain', 'river']\n",
            "Processing frames 4301-4400 for classes: ['car', 'bus', 'bike']\n",
            "Processing frames 4401-4500 for classes: ['person', 'face']\n",
            "Creating the final summarized video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Writing video: 100%|██████████| 1646/1646 [00:06<00:00, 261.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final summarized video saved to /content/cheq_summ.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 100\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "width, height = video_info.resolution_wh\n",
        "total_frames = video_info.total_frames\n",
        "\n",
        "all_frames = []\n",
        "frame_counter = 0\n",
        "\n",
        "print(\"Processing video in batches...\")\n",
        "\n",
        "while True:\n",
        "    frame_batch = []\n",
        "    try:\n",
        "        for _ in range(BATCH_SIZE):\n",
        "            frame = next(frame_generator)\n",
        "            frame_batch.append(frame)\n",
        "            frame_counter += 1\n",
        "    except StopIteration:\n",
        "        break  # Exit loop if no more frames are available\n",
        "\n",
        "    if not frame_batch:\n",
        "        break  # Exit if no frames were collected in the batch\n",
        "\n",
        "    # Round-robin processing\n",
        "    if (frame_counter // BATCH_SIZE) % 3 == 0:\n",
        "        print(f\"Processing frames {frame_counter-BATCH_SIZE+1}-{frame_counter} for classes: ['person', 'face']\")\n",
        "        human_frames = detect_and_extract_frames(frame_batch, [\"person\", \"face\"])\n",
        "        all_frames.extend(human_frames)\n",
        "    elif (frame_counter // BATCH_SIZE) % 3 == 1:\n",
        "        print(f\"Processing frames {frame_counter-BATCH_SIZE+1}-{frame_counter} for classes: ['tree', 'mountain', 'river']\")\n",
        "        nature_frames = detect_and_extract_frames(frame_batch, [\"tree\", \"mountain\", \"river\"])\n",
        "        all_frames.extend(nature_frames)\n",
        "    elif (frame_counter // BATCH_SIZE) % 3 == 2:\n",
        "        print(f\"Processing frames {frame_counter-BATCH_SIZE+1}-{frame_counter} for classes: ['car', 'bus', 'bike']\")\n",
        "        vehicle_frames = detect_and_extract_frames(frame_batch, [\"car\", \"bus\", \"bike\"])\n",
        "        all_frames.extend(vehicle_frames)\n",
        "\n",
        "print(\"Creating the final summarized video...\")\n",
        "if all_frames:\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = video_info.fps\n",
        "    out = cv2.VideoWriter(TARGET_VIDEO_PATH, fourcc, fps, (width, height))\n",
        "\n",
        "    for frame in tqdm(all_frames, desc=\"Writing video\"):\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "\n",
        "print(f\"Final summarized video saved to {TARGET_VIDEO_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wDzg0nsUuxQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}